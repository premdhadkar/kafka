= Monitoring with Confluent Control Center

== Preparing the cluster

. Enter into the `base` container:
+
[source,subs="verbatim,quotes"]
--
$ *docker-compose exec base /bin/bash*
root@base:/#
--

. To create the `temperatures_topic`:
+
[source,subs="verbatim,quotes"]
--
root@base:/# *kafka-topics --zookeeper zk-1:2181 \
    --create \
    --partitions 6 \
    --replication-factor 3 \
    --topic temperatures_topic*
--

. To delete the `temperatures_topic` topic if needed:
+
[source,subs="verbatim,quotes"]
--
root@base:/# *kafka-topics --zookeeper zk-1:2181 \
    --delete \
    --topic temperatures_topic*
--

== Consuming data

. To consume the `temperatures_topic` we can use the following command from within the `base` container:
+
[source,subs="verbatim,quotes"]
--
root@base:/# *kafka-avro-console-consumer \
    --bootstrap-server kafka-1:9092 \
    --group console-reader \
    --consumer-property client.id=consumer-1 \
    --from-beginning \
    --consumer-property interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor \
    --consumer-property confluent.monitoring.interceptor.bootstrap.servers=kafka-1:9092 \
    --property print.key=true \
    --property schema.registry.url=http://schema-registry:8081 \
    --topic temperatures_topic*
--
+
You might want to run multiple instances of the consumer... In this case chose a different `client.id` for each instance to distinguish them e.g. in Control Center.
